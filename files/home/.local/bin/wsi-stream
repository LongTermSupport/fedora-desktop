#!/usr/bin/env python3
"""
WSI-Stream - Streaming Speech-to-Text with Real-time Transcription
===================================================================
Transcribes in real-time to a buffer file, then pastes instantly on stop.

WORKFLOW:
  1. Press Insert -> starts recording, transcription runs in parallel
  2. Partial results stream to buffer file (user can watch if desired)
  3. Press Insert again -> instantly pastes final text (no transcription wait)

The key benefit: transcription happens DURING recording, so paste is instant.
"""

import os
import sys
import subprocess
import signal
import time
import argparse
import atexit
from pathlib import Path
from datetime import datetime

# Constants
LOG_DIR = Path.home() / ".local/share/speech-to-text"
LOG_FILE = LOG_DIR / "debug.log"
CACHE_DIR = Path.home() / ".cache/speech-to-text"
TRANSCRIPTION_FILE = CACHE_DIR / "last-transcription.txt"
BUFFER_FILE = CACHE_DIR / "streaming-buffer.txt"
# Use same PID file as wsi so extension can stop us
PID_FILE = Path("/dev/shm") / f"stt-recording-{os.getenv('USER')}.pid"

DBUS_PATH = "/org/fedoradesktop/SpeechToText"
DBUS_INTERFACE = "org.fedoradesktop.SpeechToText"

# Global state
debug_mode = False
no_notify = False
stop_requested = False
recorder = None
current_text = ""


def cleanup_on_exit():
    """Ensure IDLE signal is sent and mic is released on any exit."""
    global recorder
    try:
        emit_dbus_signal("StateChanged", "IDLE")
    except Exception:
        pass
    if recorder:
        try:
            recorder.shutdown()
        except Exception:
            pass
    # Clean up PID file
    if PID_FILE.exists():
        try:
            PID_FILE.unlink()
        except Exception:
            pass


atexit.register(cleanup_on_exit)


def log(message, level="INFO"):
    """Log message to file and stderr if debug mode."""
    timestamp = datetime.now().strftime("%Y-%m-%dT%H:%M:%S")
    log_line = f"[{timestamp}] [STREAM] [{level}] {message}"

    if debug_mode:
        print(log_line, file=sys.stderr)
        LOG_DIR.mkdir(parents=True, exist_ok=True)
        with open(LOG_FILE, "a") as f:
            f.write(log_line + "\n")


def emit_dbus_signal(signal_name, value):
    """Emit DBus signal for extension communication."""
    try:
        subprocess.run([
            "gdbus", "emit", "--session",
            "--object-path", DBUS_PATH,
            "--signal", f"{DBUS_INTERFACE}.{signal_name}",
            value
        ], capture_output=True, timeout=1)
    except Exception as e:
        log(f"DBus signal failed: {e}", "WARN")


def notify(state, message):
    """Send notification and DBus state signal."""
    log(f"State: {state} - {message}")
    emit_dbus_signal("StateChanged", state)

    # Skip desktop notification if --no-notify was passed
    if no_notify:
        return

    try:
        subprocess.run([
            "gdbus", "call", "--session",
            "--dest", "org.freedesktop.Notifications",
            "--object-path", "/org/freedesktop/Notifications",
            "--method", "org.freedesktop.Notifications.Notify",
            "speech-to-text-stream",
            "0",
            "audio-input-microphone",
            "Speech to Text (Streaming)",
            message,
            "[]", "{}", "2000"
        ], capture_output=True, timeout=1)
    except Exception:
        pass


def copy_to_clipboard(text, use_clipboard=False):
    """Copy text to clipboard selection."""
    wm = os.environ.get("XDG_SESSION_TYPE", "unknown")

    if wm == "wayland":
        cmd = ["wl-copy"] if use_clipboard else ["wl-copy", "-p"]
    elif wm == "x11":
        cmd = ["xsel", "-ib"] if use_clipboard else ["xsel", "-ip"]
    else:
        log(f"Unknown window manager: {wm}", "ERROR")
        return False

    try:
        proc = subprocess.Popen(cmd, stdin=subprocess.PIPE)
        proc.communicate(input=text.encode())
        return proc.returncode == 0
    except Exception as e:
        log(f"Clipboard copy failed: {e}", "ERROR")
        return False


def auto_paste(text, skip_enter=False):
    """Paste text at cursor using ydotool."""
    if not copy_to_clipboard(text, use_clipboard=False):
        return False

    time.sleep(0.05)

    env = os.environ.copy()
    env["YDOTOOL_SOCKET"] = "/run/ydotool.socket"

    try:
        # Simulate Shift+Insert (42=Shift, 110=Insert)
        subprocess.run(
            ["ydotool", "key", "42:1", "110:1", "110:0", "42:0"],
            env=env, check=True, timeout=5
        )
        log("Paste simulated via Shift+Insert")

        # Longer delay for longer text
        delay = min(0.3 + len(text) * 0.002, 1.0)
        time.sleep(delay)

        if not skip_enter:
            subprocess.run(
                ["ydotool", "key", "28:1", "28:0"],
                env=env, check=True, timeout=5
            )
            log("Enter key sent")

        return True
    except Exception as e:
        log(f"Auto-paste failed: {e}", "ERROR")
        return False


def on_realtime_update(new_text):
    """
    Callback for real-time transcription - writes to buffer file.
    File is completely replaced each time (no append/diff needed).
    """
    global current_text

    if not new_text:
        return

    new_text = new_text.strip()
    if not new_text:
        return

    # Capitalize first letter
    new_text = new_text[0].upper() + new_text[1:] if len(new_text) > 1 else new_text.upper()

    current_text = new_text
    log(f"Partial: '{new_text}'")

    # Write complete current transcription to buffer file
    # This overwrites previous content - clean and simple
    try:
        CACHE_DIR.mkdir(parents=True, exist_ok=True)
        BUFFER_FILE.write_text(new_text)
    except Exception as e:
        log(f"Buffer write failed: {e}", "WARN")


def check_dependencies():
    """Verify RealtimeSTT and ydotool are available."""
    # Check ydotool for auto-paste mode
    if not Path("/run/ydotool.socket").exists():
        log("ydotool socket not found (needed for auto-paste)", "WARN")

    try:
        import RealtimeSTT
        log("RealtimeSTT imported successfully")
        return True
    except ImportError as e:
        log(f"RealtimeSTT not installed: {e}", "ERROR")
        notify("ERROR", "RealtimeSTT not installed\n\npip install --user RealtimeSTT")
        return False


def run_streaming(args):
    """Main streaming transcription."""
    global debug_mode, no_notify, stop_requested, recorder, current_text
    debug_mode = args.debug
    no_notify = args.no_notify
    stop_requested = False
    current_text = ""

    log(f"Starting streaming transcription (pre-buffer: {args.pre_buffer})...")

    # Route to appropriate implementation
    if args.pre_buffer:
        return run_prebuffered_streaming(args)
    else:
        return run_standard_streaming(args)


def run_standard_streaming(args):
    """Standard streaming mode - RealtimeSTT manages audio."""
    global debug_mode, no_notify, stop_requested, recorder, current_text

    if not check_dependencies():
        return 1

    from RealtimeSTT import AudioToTextRecorder
    import threading

    # Write PID file
    PID_FILE.write_text(str(os.getpid()))
    log(f"PID file written: {PID_FILE}")

    # Clear buffer file
    CACHE_DIR.mkdir(parents=True, exist_ok=True)
    BUFFER_FILE.write_text("")

    # Use "base" model for streaming by default (faster loading)
    # "base" (74M params, ~142MB) loads ~3x faster than "small" (244M params, ~466MB)
    # with minimal accuracy trade-off. Override with WHISPER_MODEL env var if needed.
    model_size = os.environ.get("WHISPER_MODEL", "base")
    # Language from arg, then env, then default to English
    language = args.language or os.environ.get("WHISPER_LANGUAGE", "en") or None
    log(f"Using model: {model_size}, language: {language or 'auto-detect'}")

    final_text = ""
    recorder_error = None
    recording_done = threading.Event()

    def recording_thread():
        """Run recorder in thread so main thread can handle signals."""
        nonlocal final_text, recorder_error
        try:
            # Blocks until stop() or shutdown() is called
            final_text = recorder.text()
            log(f"Final from recorder: {final_text}")
        except Exception as e:
            recorder_error = e
            log(f"Recorder thread error: {e}", "ERROR")
        finally:
            recording_done.set()

    # Signal handler - stop recording on SIGINT/SIGTERM
    def handle_signal(signum, frame):
        global stop_requested, recorder
        log(f"Signal {signum} received, stopping...")
        stop_requested = True
        if recorder:
            try:
                recorder.stop()
                log("Called recorder.stop()")
            except Exception as e:
                log(f"stop() failed: {e}", "WARN")
        # DON'T set recording_done here - let the recording thread set it
        # after recorder.text() returns with the final transcription.
        # Setting it here causes a race where we proceed before the last
        # audio chunk is transcribed, losing the final word(s).

    signal.signal(signal.SIGINT, handle_signal)
    signal.signal(signal.SIGTERM, handle_signal)

    try:
        # Signal PREPARING state (orange icon) while initializing
        notify("PREPARING", "Loading model...")

        recorder_config = {
            "model": model_size,
            "language": language,
            "silero_sensitivity": 0.4,
            # Very long silence duration - manual stop via signal
            "post_speech_silence_duration": 300.0,
            "min_length_of_recording": 0.3,
            "min_gap_between_recordings": 0.1,
            # Real-time transcription streams to buffer file
            "enable_realtime_transcription": True,
            "realtime_processing_pause": 0.2,
            "on_realtime_transcription_update": on_realtime_update,
            "spinner": False,
        }

        # Try GPU
        try:
            recorder_config["device"] = "cuda"
            recorder_config["compute_type"] = "float16"
            log("Using GPU (CUDA)")
        except Exception:
            recorder_config["device"] = "cpu"
            recorder_config["compute_type"] = "int8"
            log("Using CPU")

        recorder = AudioToTextRecorder(**recorder_config)
        log("Recorder initialized, waiting for audio pipeline...")

        # Notify user that model is loaded, now initializing audio
        notify("PREPARING", "Initializing audio...")

        # Brief delay to let microphone and audio pipeline fully initialize
        # RealtimeSTT needs time to open audio device and start processing
        time.sleep(0.5)
        log("Audio pipeline ready, starting recording")

        # Now signal RECORDING state (red icon + countdown)
        notify("RECORDING", "Recording... (transcribing live)")

        # Start recording in thread
        rec_thread = threading.Thread(target=recording_thread, daemon=True)
        rec_thread.start()

        # Wait for either completion or timeout (main thread handles signals)
        timeout = args.timeout or 30
        recording_done.wait(timeout=timeout)

        # If stop was requested but recording thread hasn't finished yet,
        # give it a few more seconds for the final transcription
        if stop_requested and not recording_done.is_set():
            log("Waiting for final transcription after stop...")
            recording_done.wait(timeout=5)

        if not recording_done.is_set():
            log(f"Timeout after {timeout}s, stopping...")
            stop_requested = True
            if recorder:
                try:
                    recorder.abort()
                except Exception:
                    pass
                try:
                    recorder.shutdown()
                except Exception:
                    pass
            # Give thread a moment to finish
            recording_done.wait(timeout=2)

        # Only raise error if it wasn't a user-requested stop
        if recorder_error and not stop_requested:
            raise recorder_error
        elif recorder_error:
            log(f"Recorder error during stop (expected): {recorder_error}")

    except Exception as e:
        log(f"Recording error: {e}", "ERROR")
        notify("ERROR", f"Recording failed: {e}")
        return 1
    finally:
        if PID_FILE.exists():
            PID_FILE.unlink()
        # Ensure recorder is fully cleaned up - RealtimeSTT can leak audio resources
        if recorder:
            try:
                recorder.abort()
            except Exception:
                pass
            try:
                recorder.stop()
            except Exception:
                pass
            try:
                recorder.shutdown()
            except Exception:
                pass
            # Force garbage collection to release audio resources
            del recorder
            recorder = None
            import gc
            gc.collect()
            log("Recorder cleanup complete")
        # Always send IDLE signal on cleanup so extension resets
        emit_dbus_signal("StateChanged", "IDLE")
        log("Sent IDLE signal")

    # Use final text from recorder, fall back to buffer if empty
    if final_text and final_text.strip():
        text = final_text.strip()
    elif current_text:
        text = current_text
        log("Using buffered text (recorder returned empty)")
    else:
        # Try reading from buffer file as last resort
        try:
            text = BUFFER_FILE.read_text().strip()
            log("Using text from buffer file")
        except Exception:
            text = ""

    if not text:
        log("No speech detected", "WARN")
        notify("ERROR", "No speech detected")
        # Cleanup buffer
        if BUFFER_FILE.exists():
            BUFFER_FILE.unlink()
        return 1

    # Capitalize first letter
    text = text[0].upper() + text[1:] if len(text) > 1 else text.upper()

    # Wrap with marker if requested
    if args.wrap_marker:
        text = f'speech-to-text:"{text}"'
        log(f"Wrapped: {text}")

    log(f"Final text ({len(text)} chars): {text}")

    # Save to last-transcription file
    TRANSCRIPTION_FILE.write_text(text)

    # Cleanup buffer file
    if BUFFER_FILE.exists():
        BUFFER_FILE.unlink()

    # Output - instant because transcription already done!
    if args.auto_paste:
        log("Auto-pasting (instant - transcription was real-time)")
        # Small delay to ensure any focus changes from recorder shutdown settle
        time.sleep(0.2)
        success = auto_paste(text, skip_enter=args.no_auto_enter)
        if success:
            preview = text[:60] + "..." if len(text) > 60 else text
            notify("SUCCESS", preview)
        else:
            notify("ERROR", "Auto-paste failed")
            return 1
    else:
        log("Copying to clipboard (instant - transcription was real-time)")
        if copy_to_clipboard(text, use_clipboard=args.clipboard):
            preview = text[:60] + "..." if len(text) > 60 else text
            paste_hint = "Ctrl+V" if args.clipboard else "Middle-click"
            notify("SUCCESS", f"{preview}\n\n{paste_hint} to paste")
        else:
            notify("ERROR", "Clipboard copy failed")
            return 1

    time.sleep(1)
    emit_dbus_signal("StateChanged", "IDLE")

    log("Streaming complete - paste was instant!")
    return 0


def run_prebuffered_streaming(args):
    """
    Pre-buffered streaming mode - starts audio capture immediately while model loads.
    Provides instant startup by recording audio to buffer during model initialization.
    """
    global debug_mode, no_notify, stop_requested, recorder, current_text

    if not check_dependencies():
        return 1

    from RealtimeSTT import AudioToTextRecorder
    import threading
    import struct
    import array

    # Write PID file (use main process PID)
    PID_FILE.write_text(str(os.getpid()))
    log(f"PID file written: {PID_FILE}")

    # Clear buffer file
    CACHE_DIR.mkdir(parents=True, exist_ok=True)
    BUFFER_FILE.write_text("")

    model_size = os.environ.get("WHISPER_MODEL", "base")
    language = args.language or os.environ.get("WHISPER_LANGUAGE", "en") or None
    log(f"Using model: {model_size}, language: {language or 'auto-detect'}")

    # Start audio recording IMMEDIATELY (before model loads!)
    notify("PREPARING", "Starting recorder...")
    log("Starting pw-record immediately (pre-buffering enabled)")

    try:
        # Start pw-record to stdout pipe: 16000 Hz, mono, S16_LE format
        # This is the format RealtimeSTT expects for feed_audio()
        pw_record_cmd = [
            "pw-record",
            "--rate", "16000",
            "--channels", "1",
            "--format", "s16",
            "-"  # Output to stdout
        ]

        audio_process = subprocess.Popen(
            pw_record_cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.DEVNULL if not debug_mode else None
        )
        log(f"pw-record started with PID {audio_process.pid}")

        # Update PID file to pw-record's PID so extension can stop us
        PID_FILE.write_text(str(audio_process.pid))

        # Audio buffer for chunks captured while model loads
        audio_buffer = []
        chunk_size = 1024 * 2  # 1024 samples * 2 bytes per sample (S16_LE)
        model_ready = threading.Event()
        model_error = None

        def load_model_thread():
            """Load Whisper model in background thread."""
            global recorder
            nonlocal model_error
            try:
                notify("PREPARING", "Loading model...")
                log("Loading model in background thread...")

                recorder_config = {
                    "model": model_size,
                    "language": language,
                    "use_microphone": False,  # We'll feed audio manually
                    "silero_sensitivity": 0.4,
                    "enable_realtime_transcription": True,
                    "realtime_processing_pause": 0.2,
                    "on_realtime_transcription_update": on_realtime_update,
                    "spinner": False,
                }

                # Try GPU
                try:
                    recorder_config["device"] = "cuda"
                    recorder_config["compute_type"] = "float16"
                    log("Using GPU (CUDA)")
                except Exception:
                    recorder_config["device"] = "cpu"
                    recorder_config["compute_type"] = "int8"
                    log("Using CPU")

                recorder = AudioToTextRecorder(**recorder_config)
                log("Model loaded successfully!")
                model_ready.set()
            except Exception as e:
                model_error = e
                log(f"Model loading error: {e}", "ERROR")
                model_ready.set()

        # Start model loading in background
        model_thread = threading.Thread(target=load_model_thread, daemon=True)
        model_thread.start()

        # Buffer audio chunks while model loads
        log("Buffering audio while model loads...")
        while not model_ready.is_set():
            try:
                chunk = audio_process.stdout.read(chunk_size)
                if not chunk:
                    break
                audio_buffer.append(chunk)
                if len(audio_buffer) % 10 == 0:
                    log(f"Buffered {len(audio_buffer)} chunks ({len(audio_buffer) * chunk_size / 16000:.1f}s)")
            except Exception as e:
                log(f"Buffering error: {e}", "WARN")
                break

        # Check if model loaded successfully
        if model_error:
            raise model_error

        if not recorder:
            raise RuntimeError("Model failed to load")

        log(f"Model ready! Buffered {len(audio_buffer)} chunks ({len(audio_buffer) * chunk_size / 16000:.2f}s)")
        notify("RECORDING", "Recording... (transcribing live)")

        # Feed buffered chunks to model
        log("Feeding buffered audio to model...")
        for i, chunk in enumerate(audio_buffer):
            if stop_requested:
                break
            # Convert bytes to numpy-like array that RealtimeSTT expects
            audio_array = array.array('h', chunk)  # 'h' = signed short (int16)
            recorder.feed_audio(audio_array)
            if (i + 1) % 20 == 0:
                log(f"Fed {i + 1}/{len(audio_buffer)} buffered chunks")

        audio_buffer.clear()  # Free memory
        log("All buffered audio fed to model")

        # Continue feeding real-time audio until stop
        log("Feeding real-time audio...")
        timeout_time = time.time() + args.timeout
        while not stop_requested and time.time() < timeout_time:
            try:
                chunk = audio_process.stdout.read(chunk_size)
                if not chunk:
                    log("Audio stream ended")
                    break
                audio_array = array.array('h', chunk)
                recorder.feed_audio(audio_array)
            except Exception as e:
                log(f"Real-time feed error: {e}", "WARN")
                break

        # Stop recording
        log("Stopping audio capture...")
        stop_requested = True

        # Stop pw-record gracefully
        try:
            audio_process.terminate()
            audio_process.wait(timeout=2)
        except Exception:
            audio_process.kill()

        # Get final transcription
        log("Getting final transcription...")
        notify("TRANSCRIBING", "Finalizing transcription...")

        try:
            recorder.stop()
            final_text = recorder.text(on_recorded_chunk=lambda: None)
        except Exception as e:
            log(f"Transcription error: {e}", "ERROR")
            final_text = current_text  # Fall back to buffered partial text

        # Cleanup
        if PID_FILE.exists():
            PID_FILE.unlink()

        recorder.shutdown()
        recorder = None

        # Process final text (same as standard mode)
        if not final_text and current_text:
            final_text = current_text
            log("Using buffered text (recorder returned empty)")

        text = final_text.strip() if final_text else ""

        if not text:
            log("No speech detected", "WARN")
            notify("ERROR", "No speech detected")
            if BUFFER_FILE.exists():
                BUFFER_FILE.unlink()
            return 1

        # Capitalize first letter
        text = text[0].upper() + text[1:] if len(text) > 1 else text.upper()

        # Wrap with marker if requested
        if args.wrap_marker:
            text = f'speech-to-text:"{text}"'
            log(f"Wrapped: {text}")

        log(f"Final text ({len(text)} chars): {text}")

        # Save to last-transcription file
        TRANSCRIPTION_FILE.write_text(text)

        # Cleanup buffer file
        if BUFFER_FILE.exists():
            BUFFER_FILE.unlink()

        # Output
        if args.auto_paste:
            log("Auto-pasting (instant - transcription was real-time)")
            time.sleep(0.2)
            success = auto_paste(text, skip_enter=args.no_auto_enter)
            if success:
                preview = text[:60] + "..." if len(text) > 60 else text
                notify("SUCCESS", preview)
            else:
                notify("ERROR", "Auto-paste failed")
                return 1
        else:
            log("Copying to clipboard (instant - transcription was real-time)")
            if copy_to_clipboard(text, use_clipboard=args.clipboard):
                preview = text[:60] + "..." if len(text) > 60 else text
                paste_hint = "Ctrl+V" if args.clipboard else "Middle-click"
                notify("SUCCESS", f"{preview}\n\n{paste_hint} to paste")
            else:
                notify("ERROR", "Clipboard copy failed")
                return 1

        time.sleep(1)
        emit_dbus_signal("StateChanged", "IDLE")

        log("Pre-buffered streaming complete!")
        return 0

    except Exception as e:
        log(f"Pre-buffer streaming error: {e}", "ERROR")
        notify("ERROR", f"Recording failed: {e}")

        # Cleanup
        if 'audio_process' in locals() and audio_process:
            try:
                audio_process.kill()
            except Exception:
                pass
        if PID_FILE.exists():
            PID_FILE.unlink()
        if recorder:
            try:
                recorder.shutdown()
            except Exception:
                pass

        return 1


def main():
    parser = argparse.ArgumentParser(
        description="Streaming speech-to-text with real-time transcription"
    )
    parser.add_argument("-d", "--debug", action="store_true",
                        help="Enable debug logging")
    parser.add_argument("-c", "--clipboard", action="store_true",
                        help="Use CLIPBOARD instead of PRIMARY selection")
    parser.add_argument("-a", "--auto-paste", action="store_true",
                        help="Auto-paste at cursor position")
    parser.add_argument("--no-auto-enter", action="store_true",
                        help="Skip Enter key after auto-paste")
    parser.add_argument("-w", "--wrap-marker", action="store_true",
                        help="Wrap text with speech-to-text:\"...\"")
    parser.add_argument("-l", "--language", type=str, default=None,
                        help="Language code for transcription (e.g., 'en')")
    parser.add_argument("--timeout", type=int, default=120,
                        help="Maximum recording time in seconds (default: 120 for streaming)")
    parser.add_argument("--no-notify", action="store_true",
                        help="Suppress desktop notifications")
    parser.add_argument("--pre-buffer", action="store_true",
                        help="Start recording immediately while model loads (faster startup)")

    args = parser.parse_args()

    try:
        return run_streaming(args)
    except Exception as e:
        # Ensure critical errors are ALWAYS logged, even without debug mode
        global debug_mode
        debug_mode = True  # Force logging for crash reports
        log(f"FATAL ERROR: {e}", "CRITICAL")
        import traceback
        log(traceback.format_exc(), "CRITICAL")
        notify("ERROR", f"Script crashed: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())
