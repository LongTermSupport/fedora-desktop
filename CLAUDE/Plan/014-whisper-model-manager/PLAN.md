# Plan 014: Whisper Model Manager

**Status**: ğŸ”„ In Progress (Research & Planning)
**Created**: 2026-02-18
**Owner**: Claude Sonnet 4.6
**Priority**: Medium
**Type**: Feature Implementation

---

## Overview

The speech-to-text GNOME extension currently embeds Whisper model selection directly in the
panel dropdown menu. This creates two problems:

1. **Cluttered dropdown**: All known models are listed â€” both installed and not-installed â€”
   making the menu long and confusing. Users must scroll through ~10+ items to find what
   they need.

2. **Poor download UX**: Clicking an uninstalled model opens a raw `gnome-terminal` window
   running a Python one-liner. There is no progress feedback, no ability to cancel, no way to
   browse the full catalogue of available Whisper variants (e.g. `large-v3-turbo`,
   `distil-whisper-*`), and no way to filter by language capability or model size.

This plan replaces the current approach with:

- **Dropdown shows only installed models** (plus Auto), keeping it clean and short.
- A **"Manage Models..."** menu entry launches a dedicated `wsi-model-manager` terminal UI.
- The model manager is a standalone Python script using the **Textual** TUI framework that
  provides a browseable, filterable, downloadable model catalogue with live progress.

---

## Goals

- Keep the extension dropdown focused: only installed models + Auto are selectable.
- Build `wsi-model-manager` â€” a Python Textual TUI for discovering and downloading Whisper
  models from Hugging Face Hub.
- Support the full set of `Systran/faster-whisper-*` models (including English-only variants
  and newer models like `large-v3-turbo`).
- Show download progress within the TUI (no opaque terminal one-liners).
- Deployed via the existing Ansible speech-to-text playbook.
- Extension launches the manager via `gnome-terminal -- wsi-model-manager`.

---

## Non-Goals

- This plan does not change recording, transcription, or paste behaviour.
- This plan does not rewrite the extension architecture.
- We are not building a general-purpose HuggingFace model browser â€” only Whisper models.
- We are not replacing the GNOME Settings UI for any settings.
- No GPU/CUDA download variants (CPU-ready models only for this first version).

---

## Context & Background

### Current Model Detection (extension.js:1612-1629)

The extension detects installed models by checking whether the HuggingFace cache directory
exists:

```javascript
_checkModelInstalled(modelName) {
    const cacheDir = GLib.get_home_dir() + '/.cache/huggingface/hub';
    const modelDir = `models--Systran--faster-whisper-${modelName}`;
    const fullPath = `${cacheDir}/${modelDir}`;
    const file = Gio.File.new_for_path(fullPath);
    return file.query_exists(null);
}
```

Models live at: `~/.cache/huggingface/hub/models--Systran--faster-whisper-{name}/`

### Current Install UX (extension.js:1324-1354)

Clicking an uninstalled model runs:
```javascript
GLib.spawn_command_line_async(
    `gnome-terminal --title="Install Whisper Model" -- bash -c "${bashCmd}"`
);
```
Where `bashCmd` is:
```bash
python3 -c "from faster_whisper import WhisperModel; WhisperModel('tiny.en', device='cpu')"
```
This gives zero progress feedback and no ability to cancel.

### Research Findings

1. **No existing dedicated tool** for listing/downloading `faster-whisper` models with a TUI
   was found. All GUI tools are heavy (PySide6, Electron) and desktop-focused.

2. **`huggingface_hub`** (already installed as a dependency of faster-whisper) provides:
   - `scan_cache_dir()` â€” enumerate locally cached repos with sizes
   - `snapshot_download()` â€” download a full model repo with progress callbacks
   - `hf_hub_download()` â€” download individual files

3. **Python Textual** is the best TUI framework for this purpose:
   - Already used in the Python ecosystem on Fedora
   - Supports progress bars, tables, filtering, keyboard navigation
   - Runs inside gnome-terminal without issues

4. **Model catalogue** for faster-whisper on HuggingFace (Systran org):
   - `tiny`, `tiny.en`, `base`, `base.en`, `small`, `small.en`
   - `medium`, `medium.en`, `large-v2`, `large-v3`, `large-v3-turbo`
   - (distil variants are separate repos â€” out of scope for v1)

5. **HuggingFace Hub CLI** (`hf cache ls`) can list cached repos but is not user-friendly
   for this purpose.

---

## Architecture

### Component Overview

```
Extension dropdown (extension.js)
  â””â”€ "Manage Models..." menu item
       â””â”€ gnome-terminal -- wsi-model-manager
            â””â”€ Python Textual TUI
                 â”œâ”€ Model catalogue (hardcoded + HF Hub list)
                 â”œâ”€ Installed model detection (scan_cache_dir or glob)
                 â”œâ”€ Download with progress (snapshot_download + callbacks)
                 â””â”€ On exit: signals extension to refresh menu
```

### Extension Changes (extension.js)

- **Model section in `_buildMenu()`**: Only build menu items for models where
  `_checkModelInstalled(modelName)` returns `true` (plus Auto).
- **Remove** the â¬‡ "click to install" items from the dropdown.
- **Add** a `"Manage Models..."` menu item that calls `_openModelManager()`.
- **`_openModelManager()`**: Launches `gnome-terminal -- wsi-model-manager`.
- **On menu open**: Refresh installed model list so newly downloaded models appear.

### `wsi-model-manager` Script

A Python script at `~/.local/bin/wsi-model-manager` implementing a Textual TUI:

**Screen layout:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Whisper Model Manager              [q]uit  [d]ownload â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Filter: [________________]  Show: [All â–¾]           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Model           â”‚  Size  â”‚  Status  â”‚  Notes       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âœ“ Auto           â”‚   â€”    â”‚ Always   â”‚ Uses base/smallâ”‚
â”‚ âœ“ Base           â”‚ 142MB  â”‚ Installedâ”‚ Fast, good   â”‚
â”‚ âœ“ Small          â”‚ 466MB  â”‚ Installedâ”‚ Balanced     â”‚
â”‚   Tiny           â”‚  75MB  â”‚ Download â”‚ Fastest      â”‚
â”‚   Medium         â”‚  1.5GB â”‚ Download â”‚ Slow, great  â”‚
â”‚   Large v3       â”‚  3.0GB â”‚ Download â”‚ Best quality â”‚
â”‚   Large v3-turbo â”‚  1.6GB â”‚ Download â”‚ Fastest largeâ”‚
â”‚ â”€â”€ English-only â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚ âœ“ Tiny.en        â”‚  41MB  â”‚ Installedâ”‚ English only â”‚
â”‚   Base.en        â”‚  77MB  â”‚ Download â”‚ English only â”‚
â”‚   Small.en       â”‚  252MB â”‚ Download â”‚ English only â”‚
â”‚   Medium.en      â”‚  789MB â”‚ Download â”‚ English only â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [SPACE/Enter] Download selected  [DEL] Remove      â”‚
â”‚  Selected: Medium (1.5GB) â€” Press Enter to download â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Features:**
- Arrow keys to navigate model list
- Filter box to search by name
- Show filter: All / Installed / Not Downloaded
- Space/Enter to download selected model (with progress bar replacing status)
- Delete key to remove a model from cache (with confirmation)
- Download runs in background thread, UI remains responsive
- Model list refreshes after download completes

---

## Tasks

### Phase 1: Research & Validation

- [x] âœ… **Read current extension model handling code** (extension.js:480-529, 1324-1354, 1612-1629)
- [x] âœ… **Research available tools** â€” no suitable existing TUI found
- [x] âœ… **Confirm HuggingFace cache structure** â€” `~/.cache/huggingface/hub/models--Systran--faster-whisper-{name}/`
- [x] âœ… **Confirm `huggingface_hub` is available** â€” installed as dependency of faster-whisper
- [x] âœ… **Identify full model catalogue** for Systran org on HuggingFace Hub
- [x] âœ… **Confirm Textual is available** â€” added to pip install in playbook
- [x] âœ… **Confirm `large-v3-turbo` model name** â€” confirmed as `Systran/faster-whisper-large-v3-turbo`

### Phase 2: Build `wsi-model-manager`

- [x] âœ… **Create `files/home/.local/bin/wsi-model-manager`**
  - [x] âœ… Define full model catalogue (11 models incl. large-v2, large-v3-turbo, all EN variants)
  - [x] âœ… Implement `get_installed()` â€” checks HuggingFace cache snapshots dir
  - [x] âœ… Implement download via `snapshot_download()` in Textual Worker (background thread)
  - [x] âœ… Implement remove via `shutil.rmtree()` with `ConfirmScreen`
  - [x] âœ… Build Textual app: `DataTable` with Status/Model/Size/Lang/Description columns
  - [x] âœ… Implement filter/search via `Input` widget with live table refresh
  - [x] âœ… Download runs non-blocking; status updates via `call_from_thread()`
  - [x] âœ… Remove confirmation dialog via `ConfirmScreen` with Y/N/Esc bindings
  - [x] âœ… Script is deployed with `mode: '0755'` via Ansible

### Phase 3: Modify Extension Dropdown

- [x] âœ… **Update `_buildMenu()` model section**
  - [x] âœ… Not-installed models built with `item.visible = false` (hidden, not removed)
  - [x] âœ… Section headers (`_multilingualHeader`, `_englishOnlyHeader`) tracked for visibility
  - [x] âœ… `"â¬‡ Download more models..."` item added below model list
  - [x] âœ… Added `large-v2` and `large-v3-turbo` to `_whisperModels` array
- [x] âœ… **Add `_openModelManager()` method**
  - [x] âœ… Launches `gnome-terminal -- wsi-model-manager`
  - [x] âœ… Falls back to `xterm` if gnome-terminal unavailable
- [x] âœ… **Add `_refreshModelSection()` method**
  - [x] âœ… Re-checks install status for all models, updates `item.visible`
  - [x] âœ… Shows/hides section headers based on installed models in each group
  - [x] âœ… Called from `open-state-changed` handler on every menu open
- [x] âœ… **Removed `_installModel()` dead code**
- [x] âœ… **ESLint passes clean**

### Phase 4: Ansible Deployment

- [x] âœ… **Update `play-speech-to-text.yml`**
  - [x] âœ… Added `textual` to pip install task (alongside faster-whisper)
  - [x] âœ… Added task: `Deploy Whisper Model Manager (wsi-model-manager)` with `mode: '0755'`
- [x] âœ… **QA passes**: `./scripts/qa-all.bash` â€” 293 files (199 bash + 94 python) all OK

### Phase 5: Testing & Deployment

- [ ] â¬œ **Test `wsi-model-manager` standalone**
  - [ ] â¬œ Run script directly in terminal
  - [ ] â¬œ Verify installed models show âœ“
  - [ ] â¬œ Test download of a small model (tiny or tiny.en)
  - [ ] â¬œ Verify progress feedback during download
  - [ ] â¬œ Test remove function
  - [ ] â¬œ Test filter/search
- [ ] â¬œ **Deploy via Ansible**
  - [ ] â¬œ `ansible-playbook playbooks/imports/optional/common/play-speech-to-text.yml`
- [ ] â¬œ **Test extension changes (requires logout)**
  - [ ] â¬œ Verify model dropdown shows only installed models
  - [ ] â¬œ Verify "Manage Models..." launches manager in terminal
  - [ ] â¬œ After downloading new model, verify it appears in dropdown on next menu open
  - [ ] â¬œ Verify Auto is always present

---

## Technical Decisions

### Decision 1: TUI Framework

**Context**: Need a terminal UI for model browsing and downloading.

**Options Considered**:
1. **Textual** (Python) â€” Rich interactive TUI, tables, progress bars, keyboard nav
2. **Rich** (Python, no interaction) â€” Display only, no interactive selection
3. **Dialog/whiptail** (shell) â€” Very basic, no progress bars, limited layout
4. **Custom curses** â€” Too much work for this use case
5. **Raw bash with printf/tput** â€” Possible but fragile and limited

**Decision**: Textual (Option 1). Most capable, Python-native (consistent with other scripts),
well-documented, handles keyboard events and async operations cleanly.

**Risk**: Textual may not be installed by default. Mitigation: add to Ansible playbook as pip
install.

**Date**: 2026-02-18

---

### Decision 2: How to List Available Models

**Options Considered**:
1. **Hardcoded catalogue** â€” Fixed list matching current extension, easy to maintain
2. **Live HuggingFace API** â€” `list_models(author="Systran")` queries Hub at runtime
3. **Hybrid** â€” Hardcoded with "refresh from Hub" button for discovery

**Decision**: Hardcoded catalogue (Option 1) for v1.

**Rationale**:
- The set of faster-whisper models changes slowly (a few per year)
- API calls require network, add latency, and can fail
- Keeps the manager working offline (once models are downloaded)
- Matches how the extension currently works
- Can always upgrade to hybrid in a future plan

**Date**: 2026-02-18

---

### Decision 3: Download Implementation

**Options Considered**:
1. **`WhisperModel(name, device='cpu')`** â€” Triggers download as side effect of model load
2. **`snapshot_download(f"Systran/faster-whisper-{name}")`** â€” Explicit, progress-aware
3. **`hf_hub_download()`** â€” Per-file, too granular

**Decision**: `snapshot_download()` (Option 2).

**Rationale**:
- Download without loading the model into RAM (Option 1 allocates ~2-8GB RAM just to cache)
- `snapshot_download()` supports `tqdm` callbacks for progress reporting
- Clean separation of download vs. use
- `huggingface_hub` already installed as a dep of `faster-whisper`

**Date**: 2026-02-18

---

### Decision 4: Terminal Launcher from Extension

**Options Considered**:
1. **`gnome-terminal`** â€” Default terminal, already used for model install currently
2. **`xterm`** â€” Universal fallback but ugly
3. **`$TERM` env var** â€” More portable but complex to implement in GJS
4. **Custom dialog in GNOME Shell** â€” Much more complex, requires logout to update

**Decision**: Try `gnome-terminal`, fall back to `xterm` (Options 1+2).

**Rationale**: Matches current extension behaviour. gnome-terminal is installed by default on
GNOME. The fallback ensures it works on minimal installs.

**Date**: 2026-02-18

---

### Decision 5: Menu Refresh Strategy

**Context**: After downloading a model, the extension dropdown needs to reflect the new model.

**Options Considered**:
1. **Re-check on every menu open** â€” Simple, no IPC needed
2. **DBus signal from manager** â€” Instant update but requires manager to emit signal
3. **Inotify watch on cache dir** â€” Reactive but complex in GJS
4. **Manual "Refresh" menu item** â€” User-driven, simple

**Decision**: Re-check on every menu open (Option 1).

**Rationale**:
- The `open-state-changed` signal already fires when the menu opens (extension.js:606)
- `_checkModelInstalled()` is a fast filesystem stat â€” no meaningful overhead
- No IPC complexity
- Newly downloaded models will appear the next time the user opens the menu

**Date**: 2026-02-18

---

## Dependencies

- **Depends on**: Plan 007 (resource leak fixes) â€” both touch extension.js and scripts
- **Blocks**: Nothing
- **Related**:
  - `extensions/speech-to-text@fedora-desktop/extension.js`
  - `files/home/.local/bin/wsi-model-manager` (new file)
  - `playbooks/imports/optional/common/play-speech-to-text.yml`

---

## Success Criteria

- [ ] Extension dropdown model section contains only: Auto + locally installed models
- [ ] "Manage Models..." menu item launches `wsi-model-manager` in a terminal window
- [ ] `wsi-model-manager` shows all known Whisper models with install status
- [ ] Downloading a model via the TUI works with visible progress
- [ ] After downloading, the model appears in the extension dropdown on next menu open
- [ ] Removing a model from cache via the TUI works
- [ ] Filter/search in the TUI narrows the model list
- [ ] Script runs without errors when Textual is installed
- [ ] Ansible playbook deploys the script and its dependency (textual)
- [ ] ESLint passes on modified extension.js
- [ ] QA passes on all Python/Bash files

---

## Risks & Mitigations

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| `textual` not available as RPM/pip on Fedora 42 | High | Low | Install via pip in playbook (already using pip for other deps) |
| `snapshot_download()` API changes in `huggingface_hub` | Medium | Low | Pin compatible version or use fallback to `WhisperModel()` |
| Extension menu rebuild on open causes visual glitch | Low | Medium | Only update label text and visibility, don't rebuild whole menu |
| User has models in non-standard cache location | Low | Low | Document the default cache path; out of scope for v1 |
| `gnome-terminal` not available (e.g., KDE) | Low | Very Low | Fallback to `xterm` in `_openModelManager()` |
| `large-v3-turbo` not in Systran repo under expected name | Medium | Low | Verify repo name before adding to catalogue; skip if absent |

---

## Notes & Updates

### 2026-02-18 â€” Implementation Complete (Phases 1â€“4)

All code written and QA/ESLint passing. Awaiting host deployment and testing.

**Files changed:**
- `files/home/.local/bin/wsi-model-manager` â€” new Python Textual TUI script
- `extensions/speech-to-text@fedora-desktop/extension.js` â€” dropdown now shows only
  installed models; `_refreshModelSection()` and `_openModelManager()` added; dead
  `_installModel()` removed; `large-v2` and `large-v3-turbo` added to model catalogue
- `playbooks/imports/optional/common/play-speech-to-text.yml` â€” added `textual` pip dep
  and `wsi-model-manager` deploy task

**Next step (on host):**
```bash
ansible-playbook playbooks/imports/optional/common/play-speech-to-text.yml
```
Then log out and back in for extension JS changes to take effect, and test:
1. Dropdown shows only installed models
2. "Download more models..." launches `wsi-model-manager` in terminal
3. After downloading a model, it appears in dropdown on next menu open

### 2026-02-18 â€” Plan Created

**Research phase complete.** Key findings:
- No suitable existing TUI tool found â€” need to build `wsi-model-manager`
- Python Textual is the right framework (async-capable, runs in gnome-terminal)
- `snapshot_download()` from `huggingface_hub` is the correct download API
- Extension change is straightforward: filter model items + add manager launcher
- Full model catalogue identified (see Technical Decisions â†’ Decision 2)

**Model Catalogue for `wsi-model-manager` v1:**

| Name | HF Repo | Size | English Only |
|------|---------|------|--------------|
| tiny | Systran/faster-whisper-tiny | ~75MB | No |
| base | Systran/faster-whisper-base | ~142MB | No |
| small | Systran/faster-whisper-small | ~466MB | No |
| medium | Systran/faster-whisper-medium | ~1.5GB | No |
| large-v2 | Systran/faster-whisper-large-v2 | ~3.0GB | No |
| large-v3 | Systran/faster-whisper-large-v3 | ~3.0GB | No |
| large-v3-turbo | Systran/faster-whisper-large-v3-turbo | ~1.6GB | No |
| tiny.en | Systran/faster-whisper-tiny.en | ~41MB | Yes |
| base.en | Systran/faster-whisper-base.en | ~77MB | Yes |
| small.en | Systran/faster-whisper-small.en | ~252MB | Yes |
| medium.en | Systran/faster-whisper-medium.en | ~789MB | Yes |

**Note**: `large-v3-turbo` repo name on HuggingFace needs verification before adding to
catalogue â€” confirm as `Systran/faster-whisper-large-v3-turbo` or similar.

**Next step**: Verify Textual availability on Fedora 42 and `large-v3-turbo` repo name.
Then proceed to Phase 2 (build the script).
